{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ33mh9YP4L4ldOx5mWAin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrabHamidi99/ReverseEngineeringNetworks/blob/master/ReverseEngineeringDLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlIi2OrjTBwD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, RANSACRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.memmap import dtype\n",
        "class MLP_ReLU(nn.Module):\n",
        "\n",
        "  Bias_std = 1\n",
        "\n",
        "  def __init__(self, n_in, layer_list):\n",
        "    super(MLP_ReLU, self).__init__()\n",
        "\n",
        "    self.input_dim = n_in\n",
        "\n",
        "    self.first_layer = nn.Sequential(nn.Linear(n_in, layer_list[0]), nn.ReLU())\n",
        "\n",
        "    self.hidden_layers = nn.Sequential()\n",
        "    for i in range(1, len(layer_list)):\n",
        "      self.hidden_layers.append(nn.Linear(layer_list[i - 1], layer_list[i]))\n",
        "      self.hidden_layers.append(nn.ReLU())\n",
        "\n",
        "    self.apply(self.initialize_weights)\n",
        "\n",
        "    self.output_dim = layer_list[-1]\n",
        "\n",
        "    # self.last_layer = nn.Sequential(nn.Linear(layer_list[-1], n_out), nn.ReLU())\n",
        "  \n",
        "  def forward(self, x):\n",
        "    first_layer_result = self.first_layer(x)\n",
        "    output = self.hidden_layers(first_layer_result)\n",
        "    return output\n",
        "\n",
        "  def initialize_weights(self, layer):\n",
        "    # Using He-normal and standard normal to initialize weights and biases\n",
        "    if 'linear' in str(layer.__class__).lower():\n",
        "      nn.init.kaiming_normal_(layer.weight)\n",
        "      layer.weight = nn.Parameter(torch.tensor(layer.weight, dtype=torch.float64))\n",
        "      nn.init.normal_(layer.bias)\n",
        "      layer.bias = nn.Parameter(torch.tensor(layer.bias, dtype=torch.float64))\n",
        "\n",
        "  def get_all_parameters(self):\n",
        "\n",
        "    weights = []\n",
        "    biases = []\n",
        "    for k, v in self.state_dict().items():\n",
        "      if 'weight' in k:\n",
        "        weights.append(v.T)\n",
        "      if 'bias' in k:\n",
        "        biases.append(v)\n",
        "\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "RPpxzrFCTIoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_network = MLP_ReLU(10, [20, 10, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btu2dg_5XL8i",
        "outputId": "ed58e83f-ce52-48f7-fe95-b2f654ecbe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-5fb3359c4dec>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  layer.weight = nn.Parameter(torch.tensor(layer.weight, dtype=torch.float64))\n",
            "<ipython-input-2-5fb3359c4dec>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  layer.bias = nn.Parameter(torch.tensor(layer.bias, dtype=torch.float64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_network.output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHBOE9dcIU-q",
        "outputId": "2ca5dd74-7317-4964-ae66-d1d5ffbce65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegion1D:\n",
        "\n",
        "    def __init__(self, param_min, param_max, fn_weight, fn_bias, next_layer_off):\n",
        "\n",
        "        # Region a^Tx + b = 0\n",
        "        '''\n",
        "        a: fn_weight\n",
        "        b: bn_bias\n",
        "        '''\n",
        "        self._min = param_min\n",
        "        self._max = param_max\n",
        "        self._fn_weight = fn_weight\n",
        "        self._fn_bias = fn_bias\n",
        "        self._next_layer_off = next_layer_off\n",
        "\n",
        "    def get_new_regions(self, new_weight_n, new_bias_n, n):\n",
        "        weight_n = torch.dot(self._fn_weight, new_weight_n) # <a, a'>\n",
        "        bias_n = torch.dot(self._fn_bias, new_weight_n) + new_bias_n # <b, a'> + b\n",
        "\n",
        "        if weight_n == 0:\n",
        "            min_image = bias_n\n",
        "            max_image = bias_n\n",
        "        elif weight_n >= 0:\n",
        "            min_image = weight_n * self._min + bias_n\n",
        "            max_image = weight_n * self._max + bias_n\n",
        "        else:\n",
        "            min_image = weight_n * self._max + bias_n\n",
        "            max_image = weight_n * self._min + bias_n\n",
        "        if 0 < min_image:\n",
        "            return [self]\n",
        "        elif 0 > max_image:\n",
        "            self._next_layer_off.append(n)\n",
        "            return [self]\n",
        "        else:\n",
        "            if weight_n == 0:\n",
        "                return [self]\n",
        "            else:\n",
        "                preimage = (-bias_n) / weight_n\n",
        "                next_layer_off0 = list(np.copy(self._next_layer_off))\n",
        "                next_layer_off1 = list(np.copy(self._next_layer_off))\n",
        "                if weight_n >= 0:\n",
        "                    next_layer_off0.append(n)\n",
        "                else:\n",
        "                    next_layer_off1.append(n)\n",
        "                region0 = LinearRegion1D(self._min, preimage, self._fn_weight, self._fn_bias, next_layer_off0)\n",
        "                region1 = LinearRegion1D(preimage, self._max, self._fn_weight, self._fn_bias, next_layer_off1)\n",
        "                return [region0, region1]\n",
        "\n",
        "    def next_layer(self, new_weight, new_bias):\n",
        "        # self._fn_weight = np.dot(self._fn_weight, new_weight.T).ravel()\n",
        "        self._fn_weight = self._fn_weight @ new_weight\n",
        "        self._fn_bias = self._fn_bias @ new_weight + new_bias\n",
        "        self._fn_weight[self._next_layer_off] = 0\n",
        "        self._fn_bias[self._next_layer_off] = 0\n",
        "        self._next_layer_off = []\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return self._max\n",
        "\n",
        "    @property\n",
        "    def min(self):\n",
        "        return self._min\n",
        "\n",
        "    @property\n",
        "    def fn_weight(self):\n",
        "        return self._fn_weight\n",
        "\n",
        "    @property\n",
        "    def fn_bias(self):\n",
        "        return self._fn_bias\n",
        "\n",
        "    @property\n",
        "    def next_layer_off(self):\n",
        "        return self._next_layer_off\n",
        "\n",
        "    @property\n",
        "    def dead(self):\n",
        "        return np.all(np.equal(self._fn_weight, 0))\n"
      ],
      "metadata": {
        "id": "dMT-wnP3EvLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultipleLinearRegression():\n",
        "    ''' Class that implements Multiple Linear Regression '''\n",
        "    def __init__(self):\n",
        "        self.b = 0\n",
        "        self.w = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # If there is only one feature we need to reshape input.\n",
        "        if len(X.shape) == 1:\n",
        "            X.reshape(-1, 1)\n",
        "            \n",
        "        # Add 'ones' to model coefficient b in data.\n",
        "        ones = np.ones(shape=X.shape[0]).reshape(-1, 1)\n",
        "        X = np.concatenate((ones, X), 1)\n",
        "\n",
        "        print(X.shape)\n",
        "\n",
        "\n",
        "        print(X.transpose().dot(X).shape)\n",
        "        print(np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).shape)\n",
        "        print(\"----\")\n",
        "        coeficients = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y)\n",
        "        self.b = coeficients[0]\n",
        "        self.w = coeficients[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            prediction = self.b\n",
        "\n",
        "            for xi, wi in zip(x, self.w):\n",
        "                prediction += wi * xi\n",
        "            \n",
        "            predictions.append(prediction)\n",
        "            \n",
        "        return predictions"
      ],
      "metadata": {
        "id": "gtF9_KxQFwgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = 10\n",
        "\n",
        "SAMPLE_RADIUS = int(10 * np.sqrt(INPUT_DIM)) # 10 * √d\n",
        "SAMPLE_LENGTH = int(500 * np.sqrt(INPUT_DIM)) # 500 * √d\n",
        "\n",
        "PRECISION_LINE = 0.00001\n",
        "PRECISION_BOUNDARY = 0.0001\n",
        "\n",
        "ITERATIONS = 15\n",
        "EPS = 0.001\n",
        "CHECK_EPS = 0.001\n",
        "DEDUPLICATION_EPS = 0.001\n",
        "\n",
        "torch.random.seed = 32\n",
        "np.random.seed = 32\n",
        "\n",
        "APPROX_RADIUS = 0.2\n",
        "APPROX_NUM = int(1.5 * INPUT_DIM)\n",
        "APPROX_THRESHOLD = 0.9\n",
        "\n",
        "MULTIPLE_POINTS = False  # Option for tuning approx_boundary, default is False."
      ],
      "metadata": {
        "id": "WdxEi1rCFgYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def approximate_1d(model, end_point1, end_point2, iterations_, eps, init_samples=1, precision=1e-5, use_outputs=None, single_search=False):\n",
        "  \"\"\"\n",
        "  This function sample some points in the [0, 1] intnerval and query the netowkr and calculate the slopes of the sorted queries and \n",
        "  keep the slopes which are distinct.\n",
        "  Then do the binary search over the sampled points to find\n",
        "  the correct hyperplane boundaaries basesd on the queries (different slopes results from the model)\n",
        "\n",
        "  There's two option single point and multiple point search, in multiple point we query the network a lot!\n",
        "\n",
        "  INPUTS:\n",
        "  model -> a pytorch model\n",
        "  end_point1, end_point2 -> (1d torch tensor) line segment query\n",
        "  iterations_ -> (int) number of iterations for the search queries\n",
        "  eps -> (float) epsilon threshold for comaring the slopes\n",
        "  init_samples -> (int) number of the samples to begin with\n",
        "  precision -> (float) epsilon threshold for considering two query point distinct or not\n",
        "\n",
        "  RETURN:\n",
        "  (points belong to different hyperplane on the line segment, number of sampled pointss)\n",
        "  \"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    end_point1 = end_point1.reshape(1, -1) # Making 2d array\n",
        "    end_point2 = end_point2.reshape(1, -1)\n",
        "    samples_t = torch.tensor(np.arange(0, 1.0000000001, 1./(init_samples + 1), dtype=np.float64), dtype=torch.float64) # sample points in [0, 1] with same division of the intnerval \n",
        "    total_samples = 0\n",
        "\n",
        "    for iter in range(iterations_):\n",
        "      num_samples = len(samples_t)\n",
        "      samples = torch.repeat_interleave(end_point1, repeats=num_samples, dim=0) + (samples_t.reshape(-1, 1) * (end_point2 - end_point1)) # ep1 + t(ep1 - ep2) \\forall t\n",
        "      outcomes = model(samples) # get the query of the model\n",
        "\n",
        "      total_samples += num_samples\n",
        "      output_dim = outcomes.shape[1]\n",
        "\n",
        "      if use_outputs == None:\n",
        "          outputs_used = output_dim\n",
        "      else:\n",
        "          outputs_used = use_outputs\n",
        "\n",
        "      # Calculating the slopes for all the output dim  of the hyperplanes: (f(x) - f(y)) / (x - y) for queries      \n",
        "      slopes = torch.abs(torch.divide(outcomes[1:,] - outcomes[:-1,],  torch.repeat_interleave((samples_t[1:] - samples_t[:-1])[:, None], repeats=model.output_dim, dim=1)))[:,:-1].T\n",
        "      # Check epsilon difference between calculated slopes\n",
        "      diff = torch.logical_or(torch.less(slopes[:, 1:], (1 - eps) * slopes[:, :-1]), torch.greater(slopes[:, 1:], (1 + eps) * slopes[:, :-1]))\n",
        "      diff = torch.any(diff, dim=0)\n",
        "      if single_search:\n",
        "        diff_indices = torch.nonzero(diff)[0] # signle search\n",
        "      else:\n",
        "        diff_indices = torch.nonzero(diff) # multiple search\n",
        "      end_t = samples_t[[0, -1]]\n",
        "      keep_t = samples_t[diff_indices + 1]\n",
        "\n",
        "      # Sampling middle points\n",
        "      if iter < iterations_ - 1:\n",
        "        new_t_1 = (2 * keep_t + samples_t[diff_indices]) / 3\n",
        "        new_t_2 = (2 * keep_t + samples_t[diff_indices + 2]) / 3\n",
        "        if single_search:\n",
        "          samples_t, _ = torch.sort(torch.hstack((end_t, keep_t, new_t_1, new_t_2))) # single search\n",
        "        else:\n",
        "          samples_t, _ = torch.sort((torch.vstack((end_t[:, None], keep_t, new_t_1, new_t_2))).flatten()) # multiple search\n",
        "\n",
        "      # print(samples_t)\n",
        "\n",
        "\n",
        "    # Compare the difference between sample vectors to the uniqueness threshold\n",
        "    if len(samples_t) > 0:\n",
        "      if single_search:\n",
        "        unique = np.nonzero(samples_t[1:] - samples_t[:-1] > precision)[0] # single search\n",
        "      else:\n",
        "        unique = torch.nonzero(samples_t[1:] - samples_t[:-1] > precision).flatten() # multiple search\n",
        "      output = 0.5 * (samples_t[torch.hstack((unique, torch.tensor([-1])))] + samples_t[torch.hstack((torch.tensor([0]), unique + 1))])\n",
        "    else:\n",
        "        output = samples_t\n",
        "\n",
        "    return output, total_samples\n",
        "\n",
        "def regions_1d(the_weights, the_biases, endpt1, endpt2):\n",
        "    '''\n",
        "    This function cosntruct all of the linear hyperplane of a network with its given weights and biases, over a line segment which is specified with\n",
        "    the endpt1, endpt2\n",
        "\n",
        "    INPUTS:\n",
        "    the_weights -> (torch.tensor(2d))\n",
        "    the biases -> (torch.tensor(3d))\n",
        "    endpt1, endpt2 -> 2d tensors, line segment\n",
        "\n",
        "\n",
        "    RETURN:\n",
        "    [Regions]\n",
        "    '''\n",
        "    regions = [LinearRegion1D(param_min=0., param_max=1., fn_weight=(endpt2 - endpt1), fn_bias=endpt1,\n",
        "                              next_layer_off=[])]\n",
        "    depth = len(the_weights)\n",
        "\n",
        "    for k in range(depth - 1):\n",
        "        for n in range(the_biases[k].shape[0]):\n",
        "            new_regions = []\n",
        "            for region in regions:\n",
        "                new_regions = new_regions + region.get_new_regions(the_weights[k][:, n], the_biases[k][n], n)\n",
        "            regions = new_regions\n",
        "        for region in regions:\n",
        "            region.next_layer(the_weights[k], the_biases[k])\n",
        "    for region in regions:\n",
        "        region.next_layer(the_weights[-1], the_biases[-1])\n",
        "    return regions\n",
        "\n",
        "\n",
        "def region_pts_1d(regions, param_min=-torch.inf):\n",
        "    '''\n",
        "    This function return the points alogside the line segment for all the linear depth 1 linear regions of the network\n",
        "\n",
        "    INPUTS:\n",
        "    regions -> [Regions]\n",
        "\n",
        "    RETURN:\n",
        "    ([int], [int]), the x's length of the query line segment (endpoint1 - endpoint2) * x + endpoint1\n",
        "    '''\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for region in regions:\n",
        "        if region.min == param_min:\n",
        "            pass\n",
        "        else:\n",
        "            xs.append(region.min)\n",
        "            ys.append(region.min * region.fn_weight + region.fn_bias)\n",
        "    return xs, ys\n",
        "\n",
        "\n",
        "def calculate_exact_1d(model, end_point1, end_point2):\n",
        "  '''\n",
        "  This function calculate adn return exact boundary points of first depth alongside of the linen sesgmennt\n",
        "\n",
        "  INPUTS:\n",
        "  model -> pytorch model\n",
        "  endpoint1, endpoint2 -> torch.tensor, line segmeent\n",
        "\n",
        "  RETURN:\n",
        "  ([int]), exact boundary points of the netowkrs\n",
        "  '''\n",
        "  with torch.no_grad():\n",
        "    the_weights, the_biases = model.get_all_parameters()\n",
        "    # the_biases = model.first_layer.state_dict()['0.bias']\n",
        "\n",
        "    # Construct all the linear regions, given weights and biases alongside a given line segment\n",
        "    exact_regions = regions_1d(the_weights, the_biases, end_point1, end_point2)\n",
        "\n",
        "    points, _ = region_pts_1d(exact_regions, 0)\n",
        "\n",
        "    return points\n",
        "\n",
        "def approx_boundary(model, point, radius, num_samples, threshold, iterations, eps, on_pos_side_of=None, init_samples=1, precision=1e-4, use_outputs=None, multiple_points = False):\n",
        "  dim = model.input_dim\n",
        "  results = []\n",
        "  i = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  while len(results) < num_samples:\n",
        "    if len(results) == 0 and i > 10 * num_samples:  # Heuristic stopping point\n",
        "        print(\"Exceeded maximum number of samples\")\n",
        "        return None, None, None, None, total_samples\n",
        "    i += 1\n",
        "\n",
        "    midpoint = torch.rand((dim,)) - 0.5 # Sample a point from interval [-0.5, 0.5); M\n",
        "    midpoint /= torch.linalg.norm(midpoint) # Make it a unit vector\n",
        "\n",
        "    perp = torch.rand((dim,)) - 0.5 # v\n",
        "    perp = perp - torch.dot(midpoint, perp) * midpoint # v - (v^T . M) * M      Why elementwise multiplication?!\n",
        "    perp /= torch.linalg.norm(perp)\n",
        "\n",
        "    endpt1 = point + radius * midpoint + int(50 * np.sqrt(dim)) * perp\n",
        "    endpt2 = point + radius * midpoint - int(50 * np.sqrt(dim)) * perp\n",
        "    \n",
        "    if type(on_pos_side_of) is not tuple:\n",
        "      output, samples = approximate_1d(model, endpt1, endpt2, iterations, eps, init_samples=init_samples,\n",
        "                                    precision=precision, use_outputs=use_outputs, single_search=False)\n",
        "      total_samples += samples\n",
        "\n",
        "      if len(output[1:-1]) > 0:\n",
        "        output = output[1:-1]\n",
        "        if len(results) == 0:\n",
        "          results = torch.repeat_interleave(output[None, :], repeats=endpt2.shape[0], dim=0).T * torch.repeat_interleave((endpt2 - endpt1)[None, :], repeats=output.shape[0], dim=0) # appennding result length to investigate line inn between a * (x_1 - x_2) + x_1\n",
        "        else:\n",
        "          results = torch.cat([results, torch.repeat_interleave(output[None, :], repeats=endpt2.shape[0], dim=0).T * torch.repeat_interleave((endpt2 - endpt1)[None, :], repeats=output.shape[0], dim=0)], dim=0)\n",
        "  \n",
        "  X = results[:, :-1]\n",
        "  y = results[:, -1]\n",
        "\n",
        "  mlr = RANSACRegressor(random_state=0).fit(X, y)\n",
        "  weight = np.hstack((mlr.estimator_.coef_, -1))\n",
        "  bias = mlr.estimator_.intercept_\n",
        "\n",
        "  bias /= np.linalg.norm(weight)\n",
        "  weight /= np.linalg.norm(weight)\n",
        "\n",
        "  return weight, bias, results[0, :], results, total_samples\n"
      ],
      "metadata": {
        "id": "GsFjBaxL1WkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "########\n",
        "\n",
        "approx_num1 = 0\n",
        "approx_weight1 = []\n",
        "approx_bias1 = []\n",
        "unused = []\n",
        "\n",
        "def algorithm(model, approx_num1, approx_weight1, approx_bias1, unused):\n",
        "  layer1_samples = 0\n",
        "  # Sample  midpoint at a certain radius\n",
        "\n",
        "  midpoint = torch.rand((INPUT_DIM,)) - 0.5 # Sample a point from interval [-0.5, 0.5); M\n",
        "  midpoint /= torch.linalg.norm(midpoint) # Make it a unit vector\n",
        "\n",
        "  perp = torch.rand((INPUT_DIM,)) - 0.5 # v\n",
        "  perp = perp - torch.dot(midpoint, perp) * midpoint # v - (v^T . M) * M      Why elementwise multiplication?!\n",
        "  perp /= torch.linalg.norm(perp)\n",
        "\n",
        "  endpt1 = SAMPLE_RADIUS * midpoint + (SAMPLE_LENGTH / 2) * perp # rM + lv\n",
        "  endpt2 = SAMPLE_RADIUS * midpoint - (SAMPLE_LENGTH / 2) * perp # rM - lv\n",
        "\n",
        "  # Approximate region transition points along sample segment, and check against exact answer.\n",
        "  approx_pts, samples = approximate_1d(model, endpt1, endpt2, ITERATIONS, EPS)\n",
        "\n",
        "  layer1_samples += samples\n",
        "\n",
        "  exact_pts = calculate_exact_1d(model, torch.tensor(endpt1, dtype=torch.float64), torch.tensor(endpt2, dtype=torch.float64))\n",
        "\n",
        "  # Check the precision of the estimation  \n",
        "  # for ex_pt in exact_pts:\n",
        "  #   if torch.all(torch.abs(approx_pts - ex_pt) > 1e-5):\n",
        "  #     print(ex_pt)\n",
        "  #     print(\"ERORR\")\n",
        "\n",
        "  print(\"Estimated num pts along line: %d, true num pts: %d\" % (len(approx_pts), len(exact_pts)))\n",
        "\n",
        "  ##########\n",
        "\n",
        "  for point_t in approx_pts:\n",
        "    point = (endpt2 - endpt1) * point_t + endpt1\n",
        "\n",
        "    # Check if this point lies on a hyperplane already found.\n",
        "    repeated = False\n",
        "    for m in range(approx_num1):\n",
        "        if not repeated:\n",
        "            value = np.dot(approx_weight1[m], point) + approx_bias1[m]\n",
        "            value_threshold = CHECK_EPS * np.linalg.norm(point)\n",
        "            if value_threshold > value > -value_threshold:\n",
        "                repeated = True\n",
        "\n",
        "    if not repeated: # and not (approx_num1 == network[0] and KNOWN_ARCHITECTURE):\n",
        "      # Find the boundary in the neighborhood of each point by sampling more transition points.\n",
        "      # and fitting a hyperplane.\n",
        "      weight, bias, _, pts, samples = approx_boundary(model, point, APPROX_RADIUS, APPROX_NUM,\n",
        "                                                      APPROX_THRESHOLD, ITERATIONS, EPS,\n",
        "                                                      precision=PRECISION_BOUNDARY,\n",
        "                                                      multiple_points=MULTIPLE_POINTS)\n",
        "      layer1_samples += samples\n",
        "      raise Exception()\n",
        "      if np.array(weight).shape:  # Check that a valid hyperplane was found.\n",
        "          valid = True\n",
        "          i = 0\n",
        "          extra_pts = []\n",
        "\n",
        "          # Samples points a certain distance away to see if the hyperplane extends that far unchanged.\n",
        "          while valid and i < CHECK_NUM:\n",
        "              check_point = np.random.random((INPUT_DIM,)) - 0.5\n",
        "              check_point = check_point - weight * np.dot(weight, check_point)\n",
        "              check_point = point + CHECK_RADIUS * (check_point / np.linalg.norm(check_point))\n",
        "              check_vec = CHECK_RADIUS * CHECK_EPS * weight\n",
        "              straight = is_straight(sess, check_point, check_vec, EPS)\n",
        "              layer1_samples += 3\n",
        "              if straight:\n",
        "                  valid = False\n",
        "                  unused.append((point, weight, bias))\n",
        "              i += 1\n",
        "\n",
        "          # If passes checks, add candidate hyperplane to list for layer 1.\n",
        "          if valid:\n",
        "              # Check through proposed neurons for layer 1 for duplicate weights.\n",
        "              duplicate = False\n",
        "              for n in range(0, approx_num1):\n",
        "                  if np.linalg.norm(np.abs(approx_weight1[n]) - np.abs(weight)) < DEDUPLICATION_EPS:\n",
        "                      duplicate = True\n",
        "                      break\n",
        "              if not duplicate:\n",
        "                  approx_weight1.append(weight)\n",
        "                  approx_bias1.append(bias)\n",
        "                  approx_num1 += 1\n",
        "        # elif not repeated:\n",
        "          unused.append((point, None, None))\n"
      ],
      "metadata": {
        "id": "6OJPFcabXf_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm(simple_network, approx_num1, approx_weight1, approx_bias1, unused)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "pOcQ2pmRFk0v",
        "outputId": "6026615f-a05c-49aa-9b7c-1d4f72d0fbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated num pts along line: 42, true num pts: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-89f14224f0d1>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  exact_pts = calculate_exact_1d(model, torch.tensor(endpt1, dtype=torch.float64), torch.tensor(endpt2, dtype=torch.float64))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-a3e96d19d630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox_num1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox_weight1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox_bias1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-89f14224f0d1>\u001b[0m in \u001b[0;36malgorithm\u001b[0;34m(model, approx_num1, approx_weight1, approx_bias1, unused)\u001b[0m\n\u001b[1;32m     57\u001b[0m                                                       multiple_points=MULTIPLE_POINTS)\n\u001b[1;32m     58\u001b[0m       \u001b[0mlayer1_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check that a valid hyperplane was found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m           \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CiuRxMU6Go5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}